{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/VladimirApter/ml4se_course_2025/blob/main/homeworks/ml4se_course_hw6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Модель: ChatGPT 5**\n",
    "\n",
    "**Промпт:**\n",
    "Мне нужно провести исследование подходит ли CodeBERT для задачи clone detection. Я хочу проверить это следующим образом: взять примеры из датасета BigCloneBench (https://github.com/clonebench/BigCloneBench), для каждой пары фрагментов кода получить эмбеддинги фрагментов кода с помощью CodeBERT, а затем сравнить их, с помощью косинусного сходства. Если эмбеддинги окажутся близки по этой метрике, будем считать что ответ модели CodeBERT положительный, то есть данные фрагменты кода являются клонами. Сравнивая ответ модели CodeBERT с правильным ответом из датасета определим в каком проценте случаев модель CodeBERT дала правильный ответ и на основании этого вынесем вердикт по вопросу подходит ли CodeBERT для задачи clone detection. Напиши код на python в котором с помощью CodeBERT с Hugging face будет проведено это исследование"
   ],
   "metadata": {
    "id": "B5fWlWo5frTk"
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Допущения эксперимента по Clone Detection с CodeBERT\n",
    "\n",
    "При проведении эксперимента с использованием CodeBERT для задачи clone detection были сделаны следующие допущения:\n",
    "\n",
    "1. **Выбор подвыборки датасета**\n",
    "   - Для ускорения эксперимента и уменьшения потребления памяти мы использовали **только 1000 случайных пар фрагментов кода** из датасета BigCloneBench, вместо всего датасета (сотни тысяч пар).\n",
    "\n",
    "2. **Метрика для оценки сходства**\n",
    "   - В качестве меры близости между двумя фрагментами кода использовалась **косинусная схожесть эмбеддингов**, полученных от CodeBERT.\n",
    "   - Пара считалась клоном, если косинусное сходство было **≥ 0.8** (порог выбран эмпирически).\n",
    "\n",
    "3. **Эмбеддинги фрагментов кода**\n",
    "   - Эмбеддинги получались через **mean pooling последнего слоя CodeBERT** по всем токенам.\n",
    "   - Не использовалась дополнительная агрегация или архитектуры для парного сравнения.\n",
    "\n",
    "4. **Ограничение по длине кода**\n",
    "   - Для токенизации использовалась **усечённая длина до 256 токенов**, чтобы избежать переполнения памяти.\n",
    "\n",
    "5. **Случайная выборка**\n",
    "   - Подвыборка из 1000 пар была **случайной**, что может влиять на точность оценки; результаты могут немного отличаться при другой выборке.\n",
    "\n",
    "---\n",
    "\n",
    "Эти допущения упрощают эксперимент, позволяют избежать переполнения памяти и большой длительности по времени.\n"
   ]
  },
  {
   "metadata": {
    "id": "wFjgirsDfk4r",
    "outputId": "d1dbe4b6-cb07-4c1e-b48e-4a1fef2a62ef",
    "ExecuteTime": {
     "end_time": "2025-11-12T14:27:17.690497Z",
     "start_time": "2025-11-12T14:17:13.788725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "MODEL_NAME = \"microsoft/codebert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "dataset = load_dataset(\"code_x_glue_cc_clone_detection_big_clone_bench\", split=\"validation\")\n",
    "dataset = dataset.shuffle(seed=42).select(range(1000))\n",
    "\n",
    "\n",
    "def get_embedding(code: str):\n",
    "    tokens = tokenizer(code, return_tensors=\"pt\", truncation=True, max_length=256)\n",
    "    tokens = {k: v.to(device) for k, v in tokens.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "        emb = outputs.last_hidden_state.mean(dim=1)\n",
    "    return emb.cpu().numpy()\n",
    "\n",
    "def evaluate_model(dataset, sample_size=1000, threshold=0.8):\n",
    "    n = min(sample_size, len(dataset))\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for i in tqdm(range(n)):\n",
    "        code1, code2, label = dataset[i][\"func1\"], dataset[i][\"func2\"], dataset[i][\"label\"]\n",
    "        y_true.append(label)\n",
    "\n",
    "        emb1 = get_embedding(code1)\n",
    "        emb2 = get_embedding(code2)\n",
    "\n",
    "        sim = cosine_similarity(emb1, emb2)[0][0]\n",
    "        y_pred.append(1 if sim >= threshold else 0)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    return acc\n",
    "\n",
    "accuracy = evaluate_model(dataset, sample_size=1000, threshold=0.8)\n",
    "print(f\"CodeBERT accuracy on {1000} BigCloneBench pairs: {accuracy:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [09:53<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1320\n",
      "CodeBERT accuracy on 1000 BigCloneBench pairs: 0.1320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Вывод по эксперименту с CodeBERT для Clone Detection\n",
    "\n",
    "В эксперименте была использована предобученная модель **CodeBERT**, которая генерирует эмбеддинги фрагментов кода. Для 1000 случайных пар из датасета **BigCloneBench** была вычислена точность: косинусное сходство эмбеддингов ≥ 0.8 считалось признаком клонов.\n",
    "\n",
    "**Результат эксперимента:**\n",
    "- Accuracy: **0.1320** (13.2%)\n",
    "\n",
    "**Вывод:**\n",
    "- Предобученная CodeBERT без дообучения **не способна эффективно различать клоны и неклоны**.\n"
   ]
  }
 ]
}
